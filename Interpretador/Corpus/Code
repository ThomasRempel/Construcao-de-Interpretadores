#Importando as Bibliotecas

import requests
import spacy
import bs4
from bs4 import BeautifulSoup


#CÃ³digo
nlp = spacy.load("en_core_web_sm")



  dados = requests.get(site)
  if  not 200==dados.status_code:
    return lista
  soap = BeautifulSoup(dados.content, 'html.parser')


  
  for i in soap.find_all('p'):
    espaco = nlp(i.get_text())
    for j in espaco.sents:
      lista.append(j)
  return lista

sentencas = []

html1 = pega_site("https://www.tutorialspoint.com/artificial_intelligence/artificial_intelligence_natural_language_processing.htm", [])
html2 = pega_site("https://hbr.org/2022/04/the-power-of-natural-language-processing", [])
html3 = pega_site("https://www.activestate.com/blog/how-to-do-text-summarization-with-python/", [])
html4 = pega_site("https://www.coursera.org/specializations/natural-language-processing", [])
html5 = pega_site("https://www.sas.com/en_us/insights/analytics/what-is-natural-language-processing-nlp.html", [])


sentencas.append(html1)
sentencas.append(html2)
sentencas.append(html3)
sentencas.append(html4)
sentencas.append(html5)


print(sentencas)
