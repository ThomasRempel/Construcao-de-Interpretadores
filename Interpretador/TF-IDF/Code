import pandas as pd
import numpy as np
from sklearn.preprocessing import normalize


corpus = []

words_set = set()

for doc in  corpus:
    words = doc.split(' ')
    words_set = words_set.union(set(words))
    
print('Numero de Palavras no Corpus:',len(words_set))
print('Palavras dos Corpus: \n', words_set)

n_docs = len(corpus)        
n_words_set = len(words_set) 

df_tf = pd.DataFrame(np.zeros((n_docs, n_words_set)), columns=words_set)

# TF


for i in range(n_docs):
    words = corpus[i].split(' ')
    for w in words:
        df_tf[w][i] = df_tf[w][i] + (1 / len(words))
        
df_tf

#IDF
print("IDF de: ")

idf = {}

for w in words_set:
    k = 1
        
    for i in range(n_docs):
        if w in corpus[i].split():
            k += 1
          
    idf[w] =  np.log10(n_docs / k)
    
    print(f'{w:>15}: {idf[w]:>10}' ) 
    
    #TF-IDF

df_tf_idf = df_tf.copy()

for w in words_set:
    for i in range(n_docs):
        df_tf_idf[w][i] = df_tf[w][i] * idf[w]
        
df_tf_idf
